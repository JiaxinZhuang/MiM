# MiM
***

# 0. Requirements
* Python 3.8
* PyTorch 1.13
* MONAI 0.11
* CUDA 11.7
* cuDNN 8.5
* NVIDIA GPU with compute capability 8.6

```
pip install -r requirements.txt
```

## 1. Datasets
The details of the pretraining dataset and finetuning dataset are shown in the following figures. Since these datasets are all publicly available, you can download them from their official websites.

![Pretraining dataset](./assets/pretrained_dataset.png)

![Finetuning dataset](./assets/finetune_dataset.png)


The project contains two directories, _i.e.,_
1) Pretrain
2) Finetune

We will update these codes soon.

# 2. Pretrain

# 3. Finetune
It's easy to finetune the model on your own dataset.
```
```




## Reference
```
@article{zhuang2024mim,
  title={MiM: Mask in Mask Self-Supervised Pre-Training for 3D Medical Image Analysis},
  author={Zhuang, Jiaxin and Wu, Linshan and Wang, Qiong and Vardhanabhuti, Varut and Luo, Lin and Chen, Hao},
  journal={arXiv preprint arXiv:2404.15580},
  year={2024}
}
```

## Acknowledgement
This codebase heavily references the following projects and we thanks their efforts:

- [Masked Autoencoders](https://github.com/facebookresearch/mae)
- [SwinUNETR](https://github.com/Project-MONAI/research-contributions/tree/main/SwinUNETR/Pretrain)



