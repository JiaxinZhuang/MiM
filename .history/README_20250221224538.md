# MiM
***

# 0. Requirements
```
pip install -r requirements.txt
```


## 1. Datasets
The details of the pretraining dataset and finetuning dataset are shown in the following figures.

![Pretraining dataset](./assets/pretrained_dataset.png)

![Finetuning dataset](./assets/finetune_dataset.png)


The project contains two directories, _i.e.,_
1) Pretrain
2) Finetune

We will update these codes soon.

# 2. Pretrain

# 3. Finetune



## Reference
```
@article{zhuang2024mim,
  title={MiM: Mask in Mask Self-Supervised Pre-Training for 3D Medical Image Analysis},
  author={Zhuang, Jiaxin and Wu, Linshan and Wang, Qiong and Vardhanabhuti, Varut and Luo, Lin and Chen, Hao},
  journal={arXiv preprint arXiv:2404.15580},
  year={2024}
}
```

## Acknowledgement
This codebase heavily references the following projects:

- [Masked Autoencoders](https://github.com/facebookresearch/mae)
- [SwinUNETR](https://github.com/jingshuiz/SwinUNETR)



